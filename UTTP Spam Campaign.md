YouTube’s autocensorship mechanisms are effective, but these individuals are employing relatively straightforward techniques to circumvent them. YouTube uses CSAI Match, a proprietary technology designed to combat CSAI/CSAM. CSAI Match utilizes fingerprinting and video hashing. Video hashing generates a unique digital signature or "hash" for a video file, which is a fixed-length string of characters created by processing the video’s data through an algorithm. This hash can be compared against a database of hashes from known abusive videos. Fingerprinting, on the other hand, is more complex as it does not rely on exact matches. Instead, it analyzes specific features or characteristics of the video, such as patterns in the audio, visual elements, or frame sequences, to create a "fingerprint"—a digital representation capturing the unique aspects of the video content. Typically, when violative content is detected, it is flagged for partners to review, confirm, and report in accordance with local laws and regulations. However, these individuals appear to be bypassing these measures using various methods.

During my initial encounter with these groups, they had posted a heavily censored version on YouTube itself. The title card was edited using a color-changing video filter and other techniques. This was their first method of bypassing.

Video fingerprinting algorithms are designed to detect core patterns in a video, such as shapes, movements, or scene transitions, which remain consistent even with visual effects like color changes. However, they employed multiple techniques to evade CSAI Match, including extensive color grading and audio manipulation (e.g., silencing the entire video).

One method they used involves text reversal Unicode, specifically RLO (RIGHT-TO-LEFT OVERRIDE). This technique is commonly used by hackers to disguise file extensions. For example, using RLO in the file name my-text.'U+202E'cod.exe displays it as my-text.exe.doc, making it appear as a .doc file while it is actually an .exe file. YouTube’s auto-moderation system relies heavily on keyword detection and text pattern matching. The latter could potentially address this issue, but employing RLO or Unicode characters that look visually identical but are technically different can bypass these systems. For instance, someone posting illicit links or inappropriate comments might reverse the text or use alternative Unicode characters to prevent YouTube’s automated systems from detecting the message, while still allowing other users to decode it manually.
